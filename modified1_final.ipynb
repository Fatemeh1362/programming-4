{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f556fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "import  numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7e9bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 14:24:55,324 - INFO - Starting dataset download...\n",
      "2024-07-23 14:24:55,324 - DEBUG - Reading credentials from: C:/Users/mozhdeh/Desktop/programming 4/kaggle.json\n",
      "2024-07-23 14:24:55,332 - DEBUG - Headers: {'Authorization': 'Kaggle fatemeh62:ab5f9d2ab1026d86358e745ea6ac8cf5'}\n",
      "2024-07-23 14:24:55,333 - DEBUG - Sending GET request to: https://www.kaggle.com/api/v1/datasets/download/nphantawee/pump-sensor-data\n",
      "2024-07-23 14:24:55,338 - DEBUG - Starting new HTTPS connection (1): www.kaggle.com:443\n",
      "2024-07-23 14:24:56,160 - DEBUG - https://www.kaggle.com:443 \"GET /api/v1/datasets/download/nphantawee/pump-sensor-data HTTP/1.1\" 302 0\n",
      "2024-07-23 14:24:56,160 - DEBUG - Starting new HTTPS connection (1): storage.googleapis.com:443\n",
      "2024-07-23 14:24:57,070 - DEBUG - https://storage.googleapis.com:443 \"GET /kaggle-data-sets/131138/312855/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240723%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240723T122451Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=51fccf4dc67429665782433511d165e81651d21acea93ae3cec7102002f0368de9e1946205cfc8fd3eb114e15f249339230c681c1767eb06ec652bf089ffc0b464116f1c908c74c1ca93cc31afca0caeb64a34a97b1fc01376f718aafa654b38095b5600404df6260744dc86e05b395a4d1c4338c9b81b79add3fe87dc4e28b43f8b345c4c62b167e081506f48e7853f154e55409f0c040c74f156e32517a47f1fa90ceee8839689f9bca1b3928d2184e3b3756f7928a74c2e13e573592866a6dc4ecc67d42d6bc97d7919a6e3511116baae5e40258844474710c4aaca62516c8be561410291ddd37e7695546e21d266b998410686d64413aa782d24f08c98c7 HTTP/1.1\" 200 38873832\n",
      "2024-07-23 14:24:57,070 - DEBUG - Saving zip file to: C:\\Users\\mozhdeh\\Desktop\\programming 4\\pump-sensor-data.zip\n",
      "2024-07-23 14:25:03,088 - INFO - Extracting dataset...\n",
      "2024-07-23 14:25:03,861 - INFO - Dataset download and extraction completed.\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def download_dataset(api_url, destination_folder):\n",
    "    try:\n",
    "        logging.info(\"Starting dataset download...\")\n",
    "        \n",
    "        # Load Kaggle API credentials\n",
    "        credentials_file = 'C:/Users/mozhdeh/Desktop/programming 4/kaggle.json'\n",
    "        logging.debug(f\"Reading credentials from: {credentials_file}\")\n",
    "        \n",
    "        with open(credentials_file) as f:\n",
    "            kaggle_creds = json.load(f)\n",
    "        \n",
    "        # Access credentials correctly\n",
    "        username = kaggle_creds['username']\n",
    "        api_key = kaggle_creds['key']\n",
    "        headers = {'Authorization': f'Kaggle {username}:{api_key}'}\n",
    "        logging.debug(f\"Headers: {headers}\")\n",
    "        \n",
    "        # Send a GET request to download the dataset\n",
    "        logging.debug(f\"Sending GET request to: {api_url}\")\n",
    "        response = requests.get(api_url, headers=headers, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        \n",
    "        # Save the zip file\n",
    "        zip_path = os.path.join(destination_folder, 'pump-sensor-data.zip')\n",
    "        logging.debug(f\"Saving zip file to: {zip_path}\")\n",
    "        \n",
    "        with open(zip_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        \n",
    "        # Extract the zip file\n",
    "        logging.info(\"Extracting dataset...\")\n",
    "        \n",
    "        with ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(destination_folder)\n",
    "        \n",
    "        # Clean up by removing the zip file\n",
    "        os.remove(zip_path)\n",
    "        \n",
    "        logging.info(\"Dataset download and extraction completed.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error: {e}\")\n",
    "\n",
    "# Specify the destination folder\n",
    "destination_folder = r\"C:\\Users\\mozhdeh\\Desktop\\programming 4\"\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Call the function to download and extract the dataset\n",
    "download_dataset('https://www.kaggle.com/api/v1/datasets/download/nphantawee/pump-sensor-data', destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a13d99cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sensor_00</th>\n",
       "      <th>sensor_01</th>\n",
       "      <th>sensor_02</th>\n",
       "      <th>sensor_03</th>\n",
       "      <th>sensor_04</th>\n",
       "      <th>sensor_05</th>\n",
       "      <th>sensor_06</th>\n",
       "      <th>sensor_07</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_43</th>\n",
       "      <th>sensor_44</th>\n",
       "      <th>sensor_45</th>\n",
       "      <th>sensor_46</th>\n",
       "      <th>sensor_47</th>\n",
       "      <th>sensor_48</th>\n",
       "      <th>sensor_49</th>\n",
       "      <th>sensor_50</th>\n",
       "      <th>sensor_51</th>\n",
       "      <th>machine_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-01 00:00:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.375000</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-01 00:01:00</td>\n",
       "      <td>2.465394</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.310760</td>\n",
       "      <td>634.375000</td>\n",
       "      <td>76.45975</td>\n",
       "      <td>13.41146</td>\n",
       "      <td>16.13136</td>\n",
       "      <td>...</td>\n",
       "      <td>41.92708</td>\n",
       "      <td>39.641200</td>\n",
       "      <td>65.68287</td>\n",
       "      <td>50.92593</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>157.9861</td>\n",
       "      <td>67.70834</td>\n",
       "      <td>243.0556</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-04-01 00:02:00</td>\n",
       "      <td>2.444734</td>\n",
       "      <td>47.35243</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.397570</td>\n",
       "      <td>638.888900</td>\n",
       "      <td>73.54598</td>\n",
       "      <td>13.32465</td>\n",
       "      <td>16.03733</td>\n",
       "      <td>...</td>\n",
       "      <td>41.66666</td>\n",
       "      <td>39.351852</td>\n",
       "      <td>65.39352</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194443</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>67.12963</td>\n",
       "      <td>241.3194</td>\n",
       "      <td>203.7037</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-01 00:03:00</td>\n",
       "      <td>2.460474</td>\n",
       "      <td>47.09201</td>\n",
       "      <td>53.168400</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>628.125000</td>\n",
       "      <td>76.98898</td>\n",
       "      <td>13.31742</td>\n",
       "      <td>16.24711</td>\n",
       "      <td>...</td>\n",
       "      <td>40.88541</td>\n",
       "      <td>39.062500</td>\n",
       "      <td>64.81481</td>\n",
       "      <td>51.21528</td>\n",
       "      <td>38.194440</td>\n",
       "      <td>155.9606</td>\n",
       "      <td>66.84028</td>\n",
       "      <td>240.4514</td>\n",
       "      <td>203.1250</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-04-01 00:04:00</td>\n",
       "      <td>2.445718</td>\n",
       "      <td>47.13541</td>\n",
       "      <td>53.211800</td>\n",
       "      <td>46.397568</td>\n",
       "      <td>636.458300</td>\n",
       "      <td>76.58897</td>\n",
       "      <td>13.35359</td>\n",
       "      <td>16.21094</td>\n",
       "      <td>...</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>65.10416</td>\n",
       "      <td>51.79398</td>\n",
       "      <td>38.773150</td>\n",
       "      <td>158.2755</td>\n",
       "      <td>66.55093</td>\n",
       "      <td>242.1875</td>\n",
       "      <td>201.3889</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220315</th>\n",
       "      <td>220315</td>\n",
       "      <td>2018-08-31 23:55:00</td>\n",
       "      <td>2.407350</td>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520830</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>634.722229</td>\n",
       "      <td>64.59095</td>\n",
       "      <td>15.11863</td>\n",
       "      <td>16.65220</td>\n",
       "      <td>...</td>\n",
       "      <td>38.28125</td>\n",
       "      <td>68.287030</td>\n",
       "      <td>52.37268</td>\n",
       "      <td>48.32176</td>\n",
       "      <td>41.087960</td>\n",
       "      <td>212.3843</td>\n",
       "      <td>153.64580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.1921</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220316</th>\n",
       "      <td>220316</td>\n",
       "      <td>2018-08-31 23:56:00</td>\n",
       "      <td>2.400463</td>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.564240</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>630.902771</td>\n",
       "      <td>65.83363</td>\n",
       "      <td>15.15480</td>\n",
       "      <td>16.70284</td>\n",
       "      <td>...</td>\n",
       "      <td>38.28125</td>\n",
       "      <td>66.840280</td>\n",
       "      <td>50.63657</td>\n",
       "      <td>48.03241</td>\n",
       "      <td>40.798610</td>\n",
       "      <td>213.8310</td>\n",
       "      <td>156.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.1921</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220317</th>\n",
       "      <td>220317</td>\n",
       "      <td>2018-08-31 23:57:00</td>\n",
       "      <td>2.396528</td>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520830</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>625.925903</td>\n",
       "      <td>67.29445</td>\n",
       "      <td>15.08970</td>\n",
       "      <td>16.70284</td>\n",
       "      <td>...</td>\n",
       "      <td>39.06250</td>\n",
       "      <td>65.393520</td>\n",
       "      <td>48.90046</td>\n",
       "      <td>48.03241</td>\n",
       "      <td>40.798610</td>\n",
       "      <td>217.3032</td>\n",
       "      <td>155.38190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232.0602</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220318</th>\n",
       "      <td>220318</td>\n",
       "      <td>2018-08-31 23:58:00</td>\n",
       "      <td>2.406366</td>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520832</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>635.648100</td>\n",
       "      <td>65.09175</td>\n",
       "      <td>15.11863</td>\n",
       "      <td>16.56539</td>\n",
       "      <td>...</td>\n",
       "      <td>40.62500</td>\n",
       "      <td>64.236110</td>\n",
       "      <td>47.74306</td>\n",
       "      <td>48.32176</td>\n",
       "      <td>40.509258</td>\n",
       "      <td>222.5116</td>\n",
       "      <td>153.93520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.0856</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220319</th>\n",
       "      <td>220319</td>\n",
       "      <td>2018-08-31 23:59:00</td>\n",
       "      <td>2.396528</td>\n",
       "      <td>47.69965</td>\n",
       "      <td>50.520832</td>\n",
       "      <td>43.142361</td>\n",
       "      <td>639.814800</td>\n",
       "      <td>65.45634</td>\n",
       "      <td>15.11863</td>\n",
       "      <td>16.65220</td>\n",
       "      <td>...</td>\n",
       "      <td>41.40625</td>\n",
       "      <td>62.789350</td>\n",
       "      <td>46.29630</td>\n",
       "      <td>48.90046</td>\n",
       "      <td>40.219910</td>\n",
       "      <td>227.4306</td>\n",
       "      <td>150.46300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>234.0856</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220320 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0            timestamp  sensor_00  sensor_01  sensor_02  \\\n",
       "0                0  2018-04-01 00:00:00   2.465394   47.09201  53.211800   \n",
       "1                1  2018-04-01 00:01:00   2.465394   47.09201  53.211800   \n",
       "2                2  2018-04-01 00:02:00   2.444734   47.35243  53.211800   \n",
       "3                3  2018-04-01 00:03:00   2.460474   47.09201  53.168400   \n",
       "4                4  2018-04-01 00:04:00   2.445718   47.13541  53.211800   \n",
       "...            ...                  ...        ...        ...        ...   \n",
       "220315      220315  2018-08-31 23:55:00   2.407350   47.69965  50.520830   \n",
       "220316      220316  2018-08-31 23:56:00   2.400463   47.69965  50.564240   \n",
       "220317      220317  2018-08-31 23:57:00   2.396528   47.69965  50.520830   \n",
       "220318      220318  2018-08-31 23:58:00   2.406366   47.69965  50.520832   \n",
       "220319      220319  2018-08-31 23:59:00   2.396528   47.69965  50.520832   \n",
       "\n",
       "        sensor_03   sensor_04  sensor_05  sensor_06  sensor_07  ...  \\\n",
       "0       46.310760  634.375000   76.45975   13.41146   16.13136  ...   \n",
       "1       46.310760  634.375000   76.45975   13.41146   16.13136  ...   \n",
       "2       46.397570  638.888900   73.54598   13.32465   16.03733  ...   \n",
       "3       46.397568  628.125000   76.98898   13.31742   16.24711  ...   \n",
       "4       46.397568  636.458300   76.58897   13.35359   16.21094  ...   \n",
       "...           ...         ...        ...        ...        ...  ...   \n",
       "220315  43.142361  634.722229   64.59095   15.11863   16.65220  ...   \n",
       "220316  43.142361  630.902771   65.83363   15.15480   16.70284  ...   \n",
       "220317  43.142361  625.925903   67.29445   15.08970   16.70284  ...   \n",
       "220318  43.142361  635.648100   65.09175   15.11863   16.56539  ...   \n",
       "220319  43.142361  639.814800   65.45634   15.11863   16.65220  ...   \n",
       "\n",
       "        sensor_43  sensor_44  sensor_45  sensor_46  sensor_47  sensor_48  \\\n",
       "0        41.92708  39.641200   65.68287   50.92593  38.194440   157.9861   \n",
       "1        41.92708  39.641200   65.68287   50.92593  38.194440   157.9861   \n",
       "2        41.66666  39.351852   65.39352   51.21528  38.194443   155.9606   \n",
       "3        40.88541  39.062500   64.81481   51.21528  38.194440   155.9606   \n",
       "4        41.40625  38.773150   65.10416   51.79398  38.773150   158.2755   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "220315   38.28125  68.287030   52.37268   48.32176  41.087960   212.3843   \n",
       "220316   38.28125  66.840280   50.63657   48.03241  40.798610   213.8310   \n",
       "220317   39.06250  65.393520   48.90046   48.03241  40.798610   217.3032   \n",
       "220318   40.62500  64.236110   47.74306   48.32176  40.509258   222.5116   \n",
       "220319   41.40625  62.789350   46.29630   48.90046  40.219910   227.4306   \n",
       "\n",
       "        sensor_49  sensor_50  sensor_51  machine_status  \n",
       "0        67.70834   243.0556   201.3889          NORMAL  \n",
       "1        67.70834   243.0556   201.3889          NORMAL  \n",
       "2        67.12963   241.3194   203.7037          NORMAL  \n",
       "3        66.84028   240.4514   203.1250          NORMAL  \n",
       "4        66.55093   242.1875   201.3889          NORMAL  \n",
       "...           ...        ...        ...             ...  \n",
       "220315  153.64580        NaN   231.1921          NORMAL  \n",
       "220316  156.25000        NaN   231.1921          NORMAL  \n",
       "220317  155.38190        NaN   232.0602          NORMAL  \n",
       "220318  153.93520        NaN   234.0856          NORMAL  \n",
       "220319  150.46300        NaN   234.0856          NORMAL  \n",
       "\n",
       "[220320 rows x 55 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data = pd.read_csv(\"C:/Users/mozhdeh/Desktop/programming 4/sensor.csv\")\n",
    "sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f82cf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220320, 55)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensor_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62804800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220320 entries, 0 to 220319\n",
      "Data columns (total 55 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Unnamed: 0      220320 non-null  int64  \n",
      " 1   timestamp       220320 non-null  object \n",
      " 2   sensor_00       210112 non-null  float64\n",
      " 3   sensor_01       219951 non-null  float64\n",
      " 4   sensor_02       220301 non-null  float64\n",
      " 5   sensor_03       220301 non-null  float64\n",
      " 6   sensor_04       220301 non-null  float64\n",
      " 7   sensor_05       220301 non-null  float64\n",
      " 8   sensor_06       215522 non-null  float64\n",
      " 9   sensor_07       214869 non-null  float64\n",
      " 10  sensor_08       215213 non-null  float64\n",
      " 11  sensor_09       215725 non-null  float64\n",
      " 12  sensor_10       220301 non-null  float64\n",
      " 13  sensor_11       220301 non-null  float64\n",
      " 14  sensor_12       220301 non-null  float64\n",
      " 15  sensor_13       220301 non-null  float64\n",
      " 16  sensor_14       220299 non-null  float64\n",
      " 17  sensor_15       0 non-null       float64\n",
      " 18  sensor_16       220289 non-null  float64\n",
      " 19  sensor_17       220274 non-null  float64\n",
      " 20  sensor_18       220274 non-null  float64\n",
      " 21  sensor_19       220304 non-null  float64\n",
      " 22  sensor_20       220304 non-null  float64\n",
      " 23  sensor_21       220304 non-null  float64\n",
      " 24  sensor_22       220279 non-null  float64\n",
      " 25  sensor_23       220304 non-null  float64\n",
      " 26  sensor_24       220304 non-null  float64\n",
      " 27  sensor_25       220284 non-null  float64\n",
      " 28  sensor_26       220300 non-null  float64\n",
      " 29  sensor_27       220304 non-null  float64\n",
      " 30  sensor_28       220304 non-null  float64\n",
      " 31  sensor_29       220248 non-null  float64\n",
      " 32  sensor_30       220059 non-null  float64\n",
      " 33  sensor_31       220304 non-null  float64\n",
      " 34  sensor_32       220252 non-null  float64\n",
      " 35  sensor_33       220304 non-null  float64\n",
      " 36  sensor_34       220304 non-null  float64\n",
      " 37  sensor_35       220304 non-null  float64\n",
      " 38  sensor_36       220304 non-null  float64\n",
      " 39  sensor_37       220304 non-null  float64\n",
      " 40  sensor_38       220293 non-null  float64\n",
      " 41  sensor_39       220293 non-null  float64\n",
      " 42  sensor_40       220293 non-null  float64\n",
      " 43  sensor_41       220293 non-null  float64\n",
      " 44  sensor_42       220293 non-null  float64\n",
      " 45  sensor_43       220293 non-null  float64\n",
      " 46  sensor_44       220293 non-null  float64\n",
      " 47  sensor_45       220293 non-null  float64\n",
      " 48  sensor_46       220293 non-null  float64\n",
      " 49  sensor_47       220293 non-null  float64\n",
      " 50  sensor_48       220293 non-null  float64\n",
      " 51  sensor_49       220293 non-null  float64\n",
      " 52  sensor_50       143303 non-null  float64\n",
      " 53  sensor_51       204937 non-null  float64\n",
      " 54  machine_status  220320 non-null  object \n",
      "dtypes: float64(52), int64(1), object(2)\n",
      "memory usage: 92.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sensor_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c42cb5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Unnamed: 0            timestamp  sensor_00  \\\n",
      "1970-01-01 00:00:00.000000000           0  2018-04-01 00:00:00   2.465394   \n",
      "1970-01-01 00:00:00.000000001           1  2018-04-01 00:01:00   2.465394   \n",
      "1970-01-01 00:00:00.000000002           2  2018-04-01 00:02:00   2.444734   \n",
      "1970-01-01 00:00:00.000000003           3  2018-04-01 00:03:00   2.460474   \n",
      "1970-01-01 00:00:00.000000004           4  2018-04-01 00:04:00   2.445718   \n",
      "\n",
      "                               sensor_01  sensor_02  sensor_03  sensor_04  \\\n",
      "1970-01-01 00:00:00.000000000   47.09201    53.2118  46.310760   634.3750   \n",
      "1970-01-01 00:00:00.000000001   47.09201    53.2118  46.310760   634.3750   \n",
      "1970-01-01 00:00:00.000000002   47.35243    53.2118  46.397570   638.8889   \n",
      "1970-01-01 00:00:00.000000003   47.09201    53.1684  46.397568   628.1250   \n",
      "1970-01-01 00:00:00.000000004   47.13541    53.2118  46.397568   636.4583   \n",
      "\n",
      "                               sensor_05  sensor_06  sensor_07  ...  \\\n",
      "1970-01-01 00:00:00.000000000   76.45975   13.41146   16.13136  ...   \n",
      "1970-01-01 00:00:00.000000001   76.45975   13.41146   16.13136  ...   \n",
      "1970-01-01 00:00:00.000000002   73.54598   13.32465   16.03733  ...   \n",
      "1970-01-01 00:00:00.000000003   76.98898   13.31742   16.24711  ...   \n",
      "1970-01-01 00:00:00.000000004   76.58897   13.35359   16.21094  ...   \n",
      "\n",
      "                               sensor_43  sensor_44  sensor_45  sensor_46  \\\n",
      "1970-01-01 00:00:00.000000000   41.92708  39.641200   65.68287   50.92593   \n",
      "1970-01-01 00:00:00.000000001   41.92708  39.641200   65.68287   50.92593   \n",
      "1970-01-01 00:00:00.000000002   41.66666  39.351852   65.39352   51.21528   \n",
      "1970-01-01 00:00:00.000000003   40.88541  39.062500   64.81481   51.21528   \n",
      "1970-01-01 00:00:00.000000004   41.40625  38.773150   65.10416   51.79398   \n",
      "\n",
      "                               sensor_47  sensor_48  sensor_49  sensor_50  \\\n",
      "1970-01-01 00:00:00.000000000  38.194440   157.9861   67.70834   243.0556   \n",
      "1970-01-01 00:00:00.000000001  38.194440   157.9861   67.70834   243.0556   \n",
      "1970-01-01 00:00:00.000000002  38.194443   155.9606   67.12963   241.3194   \n",
      "1970-01-01 00:00:00.000000003  38.194440   155.9606   66.84028   240.4514   \n",
      "1970-01-01 00:00:00.000000004  38.773150   158.2755   66.55093   242.1875   \n",
      "\n",
      "                               sensor_51  machine_status  \n",
      "1970-01-01 00:00:00.000000000   201.3889          NORMAL  \n",
      "1970-01-01 00:00:00.000000001   201.3889          NORMAL  \n",
      "1970-01-01 00:00:00.000000002   203.7037          NORMAL  \n",
      "1970-01-01 00:00:00.000000003   203.1250          NORMAL  \n",
      "1970-01-01 00:00:00.000000004   201.3889          NORMAL  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "sensor_data.index = pd.to_datetime(sensor_data.index)\n",
    "\n",
    "# DataFrame is named sensor_data and currently has this index\n",
    "# Convert the index to datetime\n",
    "sensor_data.index = pd.to_datetime(sensor_data.index, unit='ns')\n",
    "\n",
    "# Now,checking the first few rows to verify\n",
    "print(sensor_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51765a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970-01-01 00:00:00.000000000    2018-04-01 00:00:00\n",
      "1970-01-01 00:00:00.000000001    2018-04-01 00:01:00\n",
      "1970-01-01 00:00:00.000000002    2018-04-01 00:02:00\n",
      "1970-01-01 00:00:00.000000003    2018-04-01 00:03:00\n",
      "1970-01-01 00:00:00.000000004    2018-04-01 00:04:00\n",
      "Name: timestamp, dtype: object\n",
      "Number of duplicated timestamps: 0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first few rows of the 'timestamp' column\n",
    "print(sensor_data['timestamp'].head())\n",
    "\n",
    "# Check for any duplicated timestamps\n",
    "duplicate_timestamps = sensor_data['timestamp'].duplicated().sum()\n",
    "print(f\"Number of duplicated timestamps: {duplicate_timestamps}\")\n",
    "\n",
    "# Show some duplicated timestamps if any\n",
    "if duplicate_timestamps > 0:\n",
    "    print(sensor_data[sensor_data['timestamp'].duplicated(keep=False)].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2285acab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'timestamp', 'sensor_00', 'sensor_01', 'sensor_02',\n",
      "       'sensor_03', 'sensor_04', 'sensor_05', 'sensor_06', 'sensor_07',\n",
      "       'sensor_08', 'sensor_09', 'sensor_10', 'sensor_11', 'sensor_12',\n",
      "       'sensor_13', 'sensor_14', 'sensor_15', 'sensor_16', 'sensor_17',\n",
      "       'sensor_18', 'sensor_19', 'sensor_20', 'sensor_21', 'sensor_22',\n",
      "       'sensor_23', 'sensor_24', 'sensor_25', 'sensor_26', 'sensor_27',\n",
      "       'sensor_28', 'sensor_29', 'sensor_30', 'sensor_31', 'sensor_32',\n",
      "       'sensor_33', 'sensor_34', 'sensor_35', 'sensor_36', 'sensor_37',\n",
      "       'sensor_38', 'sensor_39', 'sensor_40', 'sensor_41', 'sensor_42',\n",
      "       'sensor_43', 'sensor_44', 'sensor_45', 'sensor_46', 'sensor_47',\n",
      "       'sensor_48', 'sensor_49', 'sensor_50', 'sensor_51', 'machine_status'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicated columns\n",
    "sensor_data = sensor_data.loc[:, ~sensor_data.columns.duplicated()]\n",
    "\n",
    "# Verify the columns to ensure duplication is resolved\n",
    "print(sensor_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "423a8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaT values: 0\n",
      "Original DataFrame shape: (220320, 55)\n",
      "Cleaned DataFrame shape: (220320, 54)\n",
      "                     Unnamed: 0  sensor_00  sensor_01  sensor_02  sensor_03  \\\n",
      "timestamp                                                                     \n",
      "2018-04-01 00:00:00           0   2.465394   47.09201    53.2118  46.310760   \n",
      "2018-04-01 00:01:00           1   2.465394   47.09201    53.2118  46.310760   \n",
      "2018-04-01 00:02:00           2   2.444734   47.35243    53.2118  46.397570   \n",
      "2018-04-01 00:03:00           3   2.460474   47.09201    53.1684  46.397568   \n",
      "2018-04-01 00:04:00           4   2.445718   47.13541    53.2118  46.397568   \n",
      "\n",
      "                     sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  \\\n",
      "timestamp                                                                    \n",
      "2018-04-01 00:00:00   634.3750   76.45975   13.41146   16.13136   15.56713   \n",
      "2018-04-01 00:01:00   634.3750   76.45975   13.41146   16.13136   15.56713   \n",
      "2018-04-01 00:02:00   638.8889   73.54598   13.32465   16.03733   15.61777   \n",
      "2018-04-01 00:03:00   628.1250   76.98898   13.31742   16.24711   15.69734   \n",
      "2018-04-01 00:04:00   636.4583   76.58897   13.35359   16.21094   15.69734   \n",
      "\n",
      "                     ...  sensor_43  sensor_44  sensor_45  sensor_46  \\\n",
      "timestamp            ...                                               \n",
      "2018-04-01 00:00:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
      "2018-04-01 00:01:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
      "2018-04-01 00:02:00  ...   41.66666  39.351852   65.39352   51.21528   \n",
      "2018-04-01 00:03:00  ...   40.88541  39.062500   64.81481   51.21528   \n",
      "2018-04-01 00:04:00  ...   41.40625  38.773150   65.10416   51.79398   \n",
      "\n",
      "                     sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  \\\n",
      "timestamp                                                                    \n",
      "2018-04-01 00:00:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "2018-04-01 00:01:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "2018-04-01 00:02:00  38.194443   155.9606   67.12963   241.3194   203.7037   \n",
      "2018-04-01 00:03:00  38.194440   155.9606   66.84028   240.4514   203.1250   \n",
      "2018-04-01 00:04:00  38.773150   158.2755   66.55093   242.1875   201.3889   \n",
      "\n",
      "                     machine_status  \n",
      "timestamp                            \n",
      "2018-04-01 00:00:00          NORMAL  \n",
      "2018-04-01 00:01:00          NORMAL  \n",
      "2018-04-01 00:02:00          NORMAL  \n",
      "2018-04-01 00:03:00          NORMAL  \n",
      "2018-04-01 00:04:00          NORMAL  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure 'timestamp' column is properly converted to datetime\n",
    "sensor_data.loc[:, 'timestamp'] = pd.to_datetime(sensor_data['timestamp'], errors='coerce')\n",
    "\n",
    "# Check for any NaT values (which are invalid timestamps)\n",
    "print(f\"Number of NaT values: {sensor_data['timestamp'].isna().sum()}\")\n",
    "\n",
    "# Drop rows with NaT values in 'timestamp'\n",
    "sensor_data_cleaned = sensor_data.dropna(subset=['timestamp'])\n",
    "\n",
    "# Set 'timestamp' as the index\n",
    "sensor_data_cleaned.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Drop any remaining unnecessary columns\n",
    "sensor_data_cleaned.drop(columns=['level_0', 'index'], errors='ignore', inplace=True)\n",
    "\n",
    "# Verify the result\n",
    "print(\"Original DataFrame shape:\", sensor_data.shape)\n",
    "print(\"Cleaned DataFrame shape:\", sensor_data_cleaned.shape)\n",
    "print(sensor_data_cleaned.head())\n",
    "# Saving cleaned data to a CSV file\n",
    "sensor_data_cleaned.to_csv('C:/Users/mozhdeh/Desktop/programming 4/cleaned_sensor_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bdbf972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Unnamed: 0  sensor_00  sensor_01  sensor_02  sensor_03  \\\n",
      "timestamp                                                                     \n",
      "2018-04-01 00:00:00           0   2.465394   47.09201    53.2118  46.310760   \n",
      "2018-04-01 00:01:00           1   2.465394   47.09201    53.2118  46.310760   \n",
      "2018-04-01 00:02:00           2   2.444734   47.35243    53.2118  46.397570   \n",
      "2018-04-01 00:03:00           3   2.460474   47.09201    53.1684  46.397568   \n",
      "2018-04-01 00:04:00           4   2.445718   47.13541    53.2118  46.397568   \n",
      "\n",
      "                     sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  \\\n",
      "timestamp                                                                    \n",
      "2018-04-01 00:00:00   634.3750   76.45975   13.41146   16.13136   15.56713   \n",
      "2018-04-01 00:01:00   634.3750   76.45975   13.41146   16.13136   15.56713   \n",
      "2018-04-01 00:02:00   638.8889   73.54598   13.32465   16.03733   15.61777   \n",
      "2018-04-01 00:03:00   628.1250   76.98898   13.31742   16.24711   15.69734   \n",
      "2018-04-01 00:04:00   636.4583   76.58897   13.35359   16.21094   15.69734   \n",
      "\n",
      "                     ...  sensor_43  sensor_44  sensor_45  sensor_46  \\\n",
      "timestamp            ...                                               \n",
      "2018-04-01 00:00:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
      "2018-04-01 00:01:00  ...   41.92708  39.641200   65.68287   50.92593   \n",
      "2018-04-01 00:02:00  ...   41.66666  39.351852   65.39352   51.21528   \n",
      "2018-04-01 00:03:00  ...   40.88541  39.062500   64.81481   51.21528   \n",
      "2018-04-01 00:04:00  ...   41.40625  38.773150   65.10416   51.79398   \n",
      "\n",
      "                     sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  \\\n",
      "timestamp                                                                    \n",
      "2018-04-01 00:00:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "2018-04-01 00:01:00  38.194440   157.9861   67.70834   243.0556   201.3889   \n",
      "2018-04-01 00:02:00  38.194443   155.9606   67.12963   241.3194   203.7037   \n",
      "2018-04-01 00:03:00  38.194440   155.9606   66.84028   240.4514   203.1250   \n",
      "2018-04-01 00:04:00  38.773150   158.2755   66.55093   242.1875   201.3889   \n",
      "\n",
      "                     machine_status  \n",
      "timestamp                            \n",
      "2018-04-01 00:00:00          NORMAL  \n",
      "2018-04-01 00:01:00          NORMAL  \n",
      "2018-04-01 00:02:00          NORMAL  \n",
      "2018-04-01 00:03:00          NORMAL  \n",
      "2018-04-01 00:04:00          NORMAL  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'C:/Users/mozhdeh/Desktop/programming 4/cleaned_sensor_data.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "sensor_data_read = pd.read_csv(file_path, parse_dates=['timestamp'], index_col='timestamp')\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify\n",
    "print(sensor_data_read.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5656865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "NaNs: 158763\n",
      "Infinite values: 0\n",
      "After initial cleaning:\n",
      "NaNs: 131040\n",
      "Infinite values: 0\n",
      "After rigorous cleaning:\n",
      "NaNs: 0\n",
      "Infinite values: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:/Users/mozhdeh/Desktop/programming 4/model.pkl']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "sensor_data = pd.read_csv('C:/Users/mozhdeh/Desktop/programming 4/cleaned_sensor_data.csv')\n",
    "\n",
    "# Convert the 'timestamp' column to datetime and set it as the index\n",
    "sensor_data['timestamp'] = pd.to_datetime(sensor_data['timestamp'])\n",
    "sensor_data.set_index('timestamp', inplace=True)\n",
    "\n",
    "# Split the dataset into three parts\n",
    "train_data = sensor_data['2018-04-01':'2018-06-30']\n",
    "test_data_july = sensor_data['2018-07-01':'2018-07-31']\n",
    "test_data_august = sensor_data['2018-08-01':'2018-08-31']\n",
    "\n",
    "# Handle missing or invalid values in the training data\n",
    "X_train = train_data.drop(columns=['machine_status'])\n",
    "y_train = train_data['machine_status']\n",
    "\n",
    "# Check for NaNs and infinite values\n",
    "print(\"Before cleaning:\")\n",
    "print(f\"NaNs: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(X_train.values).sum()}\")\n",
    "\n",
    "# Replace infinite values with NaNs\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaNs with the mean of the respective columns\n",
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "\n",
    "# Verify that there are no remaining NaNs or infinite values\n",
    "print(\"After initial cleaning:\")\n",
    "print(f\"NaNs: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(X_train.values).sum()}\")\n",
    "\n",
    "# Drop columns with more than 50% NaNs\n",
    "threshold = len(X_train) * 0.5\n",
    "X_train.dropna(axis=1, thresh=threshold, inplace=True)\n",
    "\n",
    "# Drop rows with any remaining NaNs\n",
    "X_train.dropna(axis=0, inplace=True)\n",
    "\n",
    "# Verify that there are no remaining NaNs or infinite values\n",
    "print(\"After rigorous cleaning:\")\n",
    "print(f\"NaNs: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Infinite values: {np.isinf(X_train.values).sum()}\")\n",
    "\n",
    "# Ensure y_train matches X_train after dropping rows\n",
    "y_train = y_train[X_train.index]\n",
    "\n",
    "# Create a pipeline with a scaler and a classifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have a trained model\n",
    "pipeline= IsolationForest(contamination=0.1)\n",
    "# Persist the model to the local file system\n",
    "joblib.dump(pipeline, 'C:/Users/mozhdeh/Desktop/programming 4/model.pkl')\n",
    "\n",
    "# # Define the plot_sensor_anomalies function\n",
    "# def plot_sensor_anomalies(sensor, name, df):\n",
    "#     plt.figure(figsize=(15, 5))\n",
    "#     plt.plot(df.index, df[sensor], label=sensor)\n",
    "#     anomalies = df[df['machine_status'] == 'BROKEN']\n",
    "#     plt.scatter(anomalies.index, anomalies[sensor], color='red', label='Anomaly')\n",
    "#     plt.title(f'Sensor {name} Anomalies')\n",
    "#     plt.xlabel('Time')\n",
    "#     plt.ylabel(f'{name} Readings')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     return plt\n",
    "\n",
    "# # Example usage of the plot_sensor_anomalies function\n",
    "# sensor = 'sensor_00'\n",
    "# name = 'Sensor 00'\n",
    "# plt = plot_sensor_anomalies(sensor, name, train_data)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49447860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImportError: cannot import name 'save_plot' from 'utils' (C:\\Users\\mozhdeh\\utils.py)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_plot' from 'utils' (C:\\Users\\mozhdeh\\utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_sensor_anomalies, save_plot\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlistener\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Listener\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Predictor\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'save_plot' from 'utils' (C:\\Users\\mozhdeh\\utils.py)"
     ]
    }
   ],
   "source": [
    "# test_import.py\n",
    "\n",
    "try:\n",
    "    from utils import plot_sensor_anomalies, save_plot\n",
    "    print(\"Import successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"ImportError: {e}\")\n",
    "\n",
    "# main.py\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import plot_sensor_anomalies, save_plot\n",
    "from listener import Listener\n",
    "from predictor import Predictor\n",
    "\n",
    "def main():\n",
    "    # Load configuration\n",
    "    with open('application.json', 'r') as file:\n",
    "        config = json.load(file)\n",
    "    \n",
    "    # Initialize Listener\n",
    "    listener = Listener(config)\n",
    "    \n",
    "    # Initialize Predictor\n",
    "    predictor = Predictor()\n",
    "    \n",
    "    # Example usage of Predictor class\n",
    "    # Load some data to predict on\n",
    "    data = pd.read_csv(\"C:/Users/mozhdeh/Desktop/programming 4/test_data_august.csv\")  \n",
    "    \n",
    "    # Transform data using the Predictor\n",
    "    transformed_data = predictor.transform_data(data)\n",
    "    \n",
    "    # Make predictions using the Predictor\n",
    "    predictions = predictor.predict(transformed_data)\n",
    "    \n",
    "    # Combine the predictions with the original data\n",
    "    data_with_predictions = data.merge(predictions, on='timestamp', how='left')\n",
    "    \n",
    "    # Generate and save plots for each sensor in the configuration\n",
    "    for sensor in config['sensor_names']:\n",
    "        plt = plot_sensor_anomalies(sensor, f'Sensor {sensor}', data_with_predictions)\n",
    "        save_plot(plt, f'{config[\"img_directory\"]}/{sensor}_anomalies.png')\n",
    "    \n",
    "    # Start listening for new data files\n",
    "    listener.listen()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebca086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812d3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5fbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
